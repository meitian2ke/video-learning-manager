# GPUä¼˜åŒ–ç‰ˆDockerfile - ä¸“ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# å®‰è£…ç³»ç»Ÿä¾èµ–ï¼ˆåŒ…å«FFmpegå¼€å‘åº“ï¼‰
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    ffmpeg \
    libavformat-dev \
    libavcodec-dev \
    libavdevice-dev \
    libavutil-dev \
    libavfilter-dev \
    libswscale-dev \
    libswresample-dev \
    git \
    curl \
    wget \
    xz-utils \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…cuDNN 9.1 for CUDA 11.8 - è§£å†³GPUå…¼å®¹æ€§é—®é¢˜
# ä¸‹è½½å¹¶å®‰è£…cuDNN 9.1æ¥è§£å†³"Unable to load libcudnn_ops.so.9.1.0"é”™è¯¯
RUN wget -q https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linux-x86_64/cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz \
    && tar -xf cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz \
    && cp cudnn-linux-x86_64-9.1.0.70_cuda11-archive/lib/* /usr/local/cuda/lib64/ \
    && cp cudnn-linux-x86_64-9.1.0.70_cuda11-archive/include/* /usr/local/cuda/include/ \
    && rm -rf cudnn-linux-x86_64-9.1.0.70_cuda11-archive* \
    && echo "/usr/local/cuda/lib64" >> /etc/ld.so.conf.d/cuda.conf \
    && ldconfig

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å‡çº§pipï¼ˆç›´æ¥ä½¿ç”¨python3.11ï¼‰
RUN python3.11 -m pip install --upgrade pip

# å®‰è£…Cythonå’Œavçš„å…¼å®¹ç‰ˆæœ¬ï¼ˆåœ¨å®‰è£…å…¶ä»–åŒ…ä¹‹å‰ï¼‰
RUN python3.11 -m pip install "Cython>=3.0.0"

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# é…ç½®pipä½¿ç”¨å›½å†…é•œåƒæºï¼ˆå¤§å¹…æå‡ä¸‹è½½é€Ÿåº¦ï¼‰
RUN python3.11 -m pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple/ && \
    python3.11 -m pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn

# å®‰è£…PyTorch GPUç‰ˆæœ¬ï¼ˆä½¿ç”¨å›½å†…æº + CUDA 11.8ï¼‰
RUN python3.11 -m pip install torch torchvision torchaudio \
    -i https://pypi.tuna.tsinghua.edu.cn/simple/ \
    --extra-index-url https://download.pytorch.org/whl/cu118

# è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨PyAVæ—¥å¿—ç¼–è¯‘ï¼ˆé¿å…Cythonå…¼å®¹æ€§é—®é¢˜ï¼‰
ENV PYAV_LOGGING=off

# åˆ›å»ºä¸´æ—¶ç›®å½•
RUN mkdir -p /tmp/wheels

# å¤åˆ¶æœ¬åœ°wheelæ–‡ä»¶ä½œä¸ºå¤‡ç”¨ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
# æ³¨æ„ï¼šå¦‚æœmodels/wheelsç›®å½•ä¸å­˜åœ¨ï¼Œè¿™è¡Œä¼šè¢«æ³¨é‡Šæ‰
# COPY models/wheels/* /tmp/wheels/

# å¤šå±‚çº§å®‰è£…ç­–ç•¥ - ç¨³å¦¥çš„å›é€€æœºåˆ¶
RUN echo "ğŸš€ å¼€å§‹å®‰è£…faster-whisperï¼Œä½¿ç”¨å¤šå±‚çº§å›é€€ç­–ç•¥..." && \
    # ç­–ç•¥1: å°è¯•åœ¨çº¿å®‰è£…æœ€æ–°ç‰ˆæœ¬ï¼ˆä¼˜å…ˆä½¿ç”¨é¢„ç¼–è¯‘wheelsï¼‰
    (echo "ğŸ“¦ ç­–ç•¥1: åœ¨çº¿å®‰è£…æœ€æ–°ç‰ˆæœ¬..." && \
     python3.11 -m pip install --only-binary=av "faster-whisper>=1.0.3" transformers huggingface-hub && \
     echo "âœ… åœ¨çº¿å®‰è£…æˆåŠŸ") || \
    # ç­–ç•¥2: ä½¿ç”¨æœ¬åœ°wheelæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    (echo "ğŸ“¦ ç­–ç•¥2: ä½¿ç”¨æœ¬åœ°wheelæ–‡ä»¶..." && \
     ls /tmp/wheels/*.whl 2>/dev/null && \
     python3.11 -m pip install /tmp/wheels/*.whl && \
     echo "âœ… æœ¬åœ°wheelå®‰è£…æˆåŠŸ") || \
    # ç­–ç•¥3: é™çº§åˆ°å…¼å®¹ç‰ˆæœ¬
    (echo "ğŸ“¦ ç­–ç•¥3: é™çº§åˆ°å…¼å®¹ç‰ˆæœ¬..." && \
     python3.11 -m pip install "faster-whisper==1.0.1" transformers huggingface-hub && \
     echo "âœ… å…¼å®¹ç‰ˆæœ¬å®‰è£…æˆåŠŸ") || \
    # ç­–ç•¥4: æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ - openai-whisper
    (echo "ğŸ“¦ ç­–ç•¥4: å¤‡ç”¨æ–¹æ¡ˆopenai-whisper..." && \
     python3.11 -m pip install openai-whisper transformers huggingface-hub && \
     echo "âœ… å¤‡ç”¨æ–¹æ¡ˆå®‰è£…æˆåŠŸ") || \
    # å¦‚æœæ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥
    (echo "âŒ æ‰€æœ‰å®‰è£…ç­–ç•¥éƒ½å¤±è´¥äº†ï¼" && exit 1)

# å®‰è£…å…¶ä»–ä¾èµ–
RUN python3.11 -m pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY backend/ ./backend/

# åˆ›å»ºlocal-videosç›®å½•ï¼ˆé¿å…å¤åˆ¶ç©ºç›®å½•å¯¼è‡´çš„é—®é¢˜ï¼‰
RUN mkdir -p ./local-videos

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/data/uploads \
             /app/data/videos \
             /app/data/audios \
             /app/data/thumbnails \
             /app/data/local-videos \
             /app/logs

# è®¾ç½®æ¨¡å‹ç¼“å­˜ç¯å¢ƒå˜é‡
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface

# åˆ›å»ºæ¨¡å‹ç¼“å­˜ç›®å½•
RUN mkdir -p /root/.cache/huggingface/hub

# æ¨¡å‹å°†åœ¨è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½åˆ°å®¹å™¨å†…

# è®¾ç½®æƒé™
RUN chmod -R 755 /app

# ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/backend
ENV ENVIRONMENT=production
ENV WHISPER_DEVICE=cuda
ENV WHISPER_COMPUTE_TYPE=float16
ENV WHISPER_MODEL=base
ENV MAX_CONCURRENT_TRANSCRIPTIONS=3
ENV FORCE_CPU_MODE=false

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python3.11", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]