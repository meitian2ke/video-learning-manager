# GPU优化版Dockerfile - 专为生产环境设计
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# 设置环境变量
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# 安装系统依赖（包含FFmpeg开发库）
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    ffmpeg \
    libavformat-dev \
    libavcodec-dev \
    libavdevice-dev \
    libavutil-dev \
    libavfilter-dev \
    libswscale-dev \
    libswresample-dev \
    git \
    curl \
    wget \
    xz-utils \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# 安装cuDNN 9.1 for CUDA 11.8 - 解决GPU兼容性问题
# 下载并安装cuDNN 9.1来解决"Unable to load libcudnn_ops.so.9.1.0"错误
RUN wget -q https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linux-x86_64/cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz \
    && tar -xf cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz \
    && cp cudnn-linux-x86_64-9.1.0.70_cuda11-archive/lib/* /usr/local/cuda/lib64/ \
    && cp cudnn-linux-x86_64-9.1.0.70_cuda11-archive/include/* /usr/local/cuda/include/ \
    && rm -rf cudnn-linux-x86_64-9.1.0.70_cuda11-archive* \
    && echo "/usr/local/cuda/lib64" >> /etc/ld.so.conf.d/cuda.conf \
    && ldconfig

# 设置工作目录
WORKDIR /app

# 升级pip（直接使用python3.11）
RUN python3.11 -m pip install --upgrade pip

# 复制requirements文件
COPY requirements.txt .

# 配置pip使用国内镜像源（大幅提升下载速度）
RUN python3.11 -m pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple/ && \
    python3.11 -m pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn

# 安装PyTorch GPU版本（使用国内源 + CUDA 11.8）
RUN python3.11 -m pip install torch torchvision torchaudio \
    -i https://pypi.tuna.tsinghua.edu.cn/simple/ \
    --extra-index-url https://download.pytorch.org/whl/cu118

# 先安装faster-whisper和关键依赖（确保安装成功）
# FFmpeg开发库已在上面安装，PyAV可以正常编译
RUN python3.11 -m pip install faster-whisper==0.9.0 transformers huggingface-hub -i https://pypi.tuna.tsinghua.edu.cn/simple/

# 安装其他依赖
RUN python3.11 -m pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY backend/ ./backend/

# 创建local-videos目录（避免复制空目录导致的问题）
RUN mkdir -p ./local-videos

# 创建必要的目录
RUN mkdir -p /app/data/uploads \
             /app/data/videos \
             /app/data/audios \
             /app/data/thumbnails \
             /app/data/local-videos \
             /app/logs

# 设置模型缓存环境变量
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface

# 创建模型缓存目录
RUN mkdir -p /root/.cache/huggingface/hub

# 复制预下载的模型到镜像中
COPY models/faster-whisper-large-v3 /root/.cache/huggingface/hub/models--Systran--faster-whisper-large-v3

# 设置权限
RUN chmod -R 755 /app

# 环境变量
ENV PYTHONPATH=/app/backend
ENV ENVIRONMENT=production
ENV WHISPER_DEVICE=cuda
ENV WHISPER_COMPUTE_TYPE=float16
ENV WHISPER_MODEL=base
ENV MAX_CONCURRENT_TRANSCRIPTIONS=3
ENV FORCE_CPU_MODE=false

# 健康检查
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["python3.11", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]