# GPU优化版Dockerfile - 专为生产环境设计
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# 设置环境变量
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# 安装系统依赖（包含FFmpeg开发库）
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    ffmpeg \
    libavformat-dev \
    libavcodec-dev \
    libavdevice-dev \
    libavutil-dev \
    libavfilter-dev \
    libswscale-dev \
    libswresample-dev \
    git \
    curl \
    wget \
    xz-utils \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# 安装cuDNN 9.1 for CUDA 11.8 - 解决GPU兼容性问题
# 下载并安装cuDNN 9.1来解决"Unable to load libcudnn_ops.so.9.1.0"错误
RUN wget -q https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linux-x86_64/cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz \
    && tar -xf cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz \
    && cp cudnn-linux-x86_64-9.1.0.70_cuda11-archive/lib/* /usr/local/cuda/lib64/ \
    && cp cudnn-linux-x86_64-9.1.0.70_cuda11-archive/include/* /usr/local/cuda/include/ \
    && rm -rf cudnn-linux-x86_64-9.1.0.70_cuda11-archive* \
    && echo "/usr/local/cuda/lib64" >> /etc/ld.so.conf.d/cuda.conf \
    && ldconfig

# 设置工作目录
WORKDIR /app

# 升级pip（直接使用python3.11）
RUN python3.11 -m pip install --upgrade pip

# 安装Cython和av的兼容版本（在安装其他包之前）
RUN python3.11 -m pip install "Cython>=3.0.0"

# 复制requirements文件
COPY requirements.txt .

# 配置pip使用国内镜像源（大幅提升下载速度）
RUN python3.11 -m pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple/ && \
    python3.11 -m pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn

# 安装PyTorch GPU版本（使用国内源 + CUDA 11.8）
RUN python3.11 -m pip install torch torchvision torchaudio \
    -i https://pypi.tuna.tsinghua.edu.cn/simple/ \
    --extra-index-url https://download.pytorch.org/whl/cu118

# 设置环境变量禁用PyAV日志编译（避免Cython兼容性问题）
ENV PYAV_LOGGING=off

# 创建临时目录
RUN mkdir -p /tmp/wheels

# 复制本地wheel文件作为备用（如果存在的话）
# 注意：如果models/wheels目录不存在，这行会被注释掉
# COPY models/wheels/* /tmp/wheels/

# 多层级安装策略 - 稳妥的回退机制
RUN echo "🚀 开始安装faster-whisper，使用多层级回退策略..." && \
    # 策略1: 尝试在线安装最新版本（优先使用预编译wheels）
    (echo "📦 策略1: 在线安装最新版本..." && \
     python3.11 -m pip install --only-binary=av "faster-whisper>=1.0.3" transformers huggingface-hub && \
     echo "✅ 在线安装成功") || \
    # 策略2: 使用本地wheel文件（如果存在）
    (echo "📦 策略2: 使用本地wheel文件..." && \
     ls /tmp/wheels/*.whl 2>/dev/null && \
     python3.11 -m pip install /tmp/wheels/*.whl && \
     echo "✅ 本地wheel安装成功") || \
    # 策略3: 降级到兼容版本
    (echo "📦 策略3: 降级到兼容版本..." && \
     python3.11 -m pip install "faster-whisper==1.0.1" transformers huggingface-hub && \
     echo "✅ 兼容版本安装成功") || \
    # 策略4: 最后的备用方案 - openai-whisper
    (echo "📦 策略4: 备用方案openai-whisper..." && \
     python3.11 -m pip install openai-whisper transformers huggingface-hub && \
     echo "✅ 备用方案安装成功") || \
    # 如果所有策略都失败
    (echo "❌ 所有安装策略都失败了！" && exit 1)

# 安装其他依赖
RUN python3.11 -m pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY backend/ ./backend/

# 创建local-videos目录（避免复制空目录导致的问题）
RUN mkdir -p ./local-videos

# 创建必要的目录
RUN mkdir -p /app/data/uploads \
             /app/data/videos \
             /app/data/audios \
             /app/data/thumbnails \
             /app/data/local-videos \
             /app/logs

# 设置模型缓存环境变量
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface

# 创建模型缓存目录
RUN mkdir -p /root/.cache/huggingface/hub

# 模型将在运行时自动下载到容器内

# 设置权限
RUN chmod -R 755 /app

# 环境变量
ENV PYTHONPATH=/app/backend
ENV ENVIRONMENT=production
ENV WHISPER_DEVICE=cuda
ENV WHISPER_COMPUTE_TYPE=float16
ENV WHISPER_MODEL=base
ENV MAX_CONCURRENT_TRANSCRIPTIONS=3
ENV FORCE_CPU_MODE=false

# 健康检查
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["python3.11", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]