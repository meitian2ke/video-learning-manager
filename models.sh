#!/bin/bash

# ğŸ¤– Whisperæ¨¡å‹ç®¡ç†è„šæœ¬
# ä½¿ç”¨Docker Composeç®¡ç†æ¨¡å‹ä¸‹è½½å’ŒéªŒè¯

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_status() { echo -e "${BLUE}[INFO]${NC} $1"; }
print_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
print_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
print_error() { echo -e "${RED}[ERROR]${NC} $1"; }

show_help() {
    echo "ğŸ¤– Whisperæ¨¡å‹ç®¡ç†è„šæœ¬"
    echo ""
    echo "ä½¿ç”¨æ–¹å¼:"
    echo "  ./models.sh download  - ä¸‹è½½Whisperæ¨¡å‹"
    echo "  ./models.sh verify    - éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨"
    echo "  ./models.sh status    - æŸ¥çœ‹æ¨¡å‹çŠ¶æ€"
    echo "  ./models.sh clean     - æ¸…ç†æ¨¡å‹ç¼“å­˜"
    echo ""
    exit 0
}

# ä¸‹è½½æ¨¡å‹
download_models() {
    print_status "ğŸ¤– å¼€å§‹ä¸‹è½½Whisperæ¨¡å‹..."
    
    # æ„å»ºæ¨¡å‹ä¸‹è½½é•œåƒ
    print_status "æ„å»ºæ¨¡å‹ä¸‹è½½é•œåƒ..."
    docker-compose -f docker-compose.gpu.yml build whisper-models
    
    # è¿è¡Œæ¨¡å‹ä¸‹è½½
    print_status "è¿è¡Œæ¨¡å‹ä¸‹è½½å®¹å™¨..."
    docker-compose -f docker-compose.gpu.yml --profile init run --rm whisper-models
    
    print_success "âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼"
}

# éªŒè¯æ¨¡å‹
verify_models() {
    print_status "ğŸ§ª éªŒè¯æ¨¡å‹å¯ç”¨æ€§..."
    
    # æ£€æŸ¥å·æ˜¯å¦å­˜åœ¨
    if ! docker volume inspect video-learning-manager_whisper-models > /dev/null 2>&1; then
        print_error "âŒ æ¨¡å‹å·ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹"
        echo "è¿è¡Œ: ./models.sh download"
        return 1
    fi
    
    # è¿è¡ŒéªŒè¯
    docker run --rm \
        --gpus all \
        -v video-learning-manager_whisper-models:/root/.cache/huggingface \
        -e HF_HOME=/root/.cache/huggingface \
        video-learning-manager-whisper-models \
        python3 -c "
from faster_whisper import WhisperModel
try:
    model = WhisperModel('base', device='cuda', compute_type='float16')
    print('âœ… æ¨¡å‹éªŒè¯æˆåŠŸï¼ŒGPUè½¬å½•åŠŸèƒ½å°±ç»ªï¼')
except Exception as e:
    print(f'âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}')
    exit(1)
"
    
    print_success "ğŸš€ æ¨¡å‹éªŒè¯é€šè¿‡ï¼"
}

# æŸ¥çœ‹æ¨¡å‹çŠ¶æ€
show_status() {
    print_status "ğŸ“Š æ¨¡å‹çŠ¶æ€æ£€æŸ¥..."
    
    # æ£€æŸ¥å·
    if docker volume inspect video-learning-manager_whisper-models > /dev/null 2>&1; then
        print_success "âœ… æ¨¡å‹å·å­˜åœ¨"
        
        # æ˜¾ç¤ºå·å¤§å°
        volume_size=$(docker run --rm -v video-learning-manager_whisper-models:/data alpine du -sh /data | cut -f1)
        print_status "æ¨¡å‹ç¼“å­˜å¤§å°: $volume_size"
        
        # åˆ—å‡ºæ¨¡å‹æ–‡ä»¶
        print_status "æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:"
        docker run --rm -v video-learning-manager_whisper-models:/data alpine ls -la /data/hub/ 2>/dev/null || echo "  æ— æ¨¡å‹æ–‡ä»¶"
        
    else
        print_warning "âŒ æ¨¡å‹å·ä¸å­˜åœ¨"
    fi
    
    # æ£€æŸ¥è¿è¡Œä¸­çš„æœåŠ¡
    if docker ps | grep -q video-learning-manager-gpu; then
        print_success "âœ… åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ"
    else
        print_warning "âš ï¸ åç«¯æœåŠ¡æœªè¿è¡Œ"
    fi
}

# æ¸…ç†æ¨¡å‹ç¼“å­˜
clean_models() {
    print_warning "âš ï¸ è¿™å°†åˆ é™¤æ‰€æœ‰å·²ä¸‹è½½çš„æ¨¡å‹ï¼"
    read -p "ç¡®è®¤ç»§ç»­? (y/N): " -n 1 -r
    echo
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        print_status "æ¸…ç†æ¨¡å‹ç¼“å­˜..."
        docker volume rm video-learning-manager_whisper-models 2>/dev/null || true
        print_success "âœ… æ¨¡å‹ç¼“å­˜å·²æ¸…ç†"
    else
        print_status "æ“ä½œå·²å–æ¶ˆ"
    fi
}

# ä¸»å‡½æ•°
main() {
    case "${1:-}" in
        download)
            download_models
            ;;
        verify)
            verify_models
            ;;
        status)
            show_status
            ;;
        clean)
            clean_models
            ;;
        --help|-h|"")
            show_help
            ;;
        *)
            print_error "æœªçŸ¥å‘½ä»¤: $1"
            show_help
            ;;
    esac
}

echo "ğŸ¤– Whisperæ¨¡å‹ç®¡ç†è„šæœ¬"
echo "=============================================="

main "$@"