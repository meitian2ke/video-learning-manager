import asyncio
import os
import re
from typing import Dict, Tuple, Optional, List
from pathlib import Path
import subprocess
import json
from faster_whisper import WhisperModel
from app.core.config import settings
import logging

# OpenAI API client - å»¶è¿Ÿåˆå§‹åŒ–é¿å…å¯åŠ¨é—®é¢˜
openai_client = None
try:
    from openai import OpenAI
    # å»¶è¿Ÿåˆ°å®é™…ä½¿ç”¨æ—¶å†åˆå§‹åŒ–
except ImportError:
    pass

logger = logging.getLogger(__name__)

# åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘è½¬å½•æ•°é‡
transcription_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_TRANSCRIPTIONS)

class AITranscriptionService:
    def __init__(self):
        self.model = None
        # ä¸åœ¨åˆå§‹åŒ–æ—¶åŠ è½½æ¨¡å‹ï¼Œé‡‡ç”¨æ‡’åŠ è½½æ¨¡å¼
    
    def _ensure_model_loaded(self):
        """ç¡®ä¿æ¨¡å‹å·²åŠ è½½ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self.model is None:
            try:
                logger.info(f"æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {settings.WHISPER_MODEL}")
                self.model = WhisperModel(
                    settings.WHISPER_MODEL,
                    device=settings.WHISPER_DEVICE,
                    compute_type=settings.WHISPER_COMPUTE_TYPE,
                    num_workers=getattr(settings, 'WHISPER_NUM_WORKERS', 1),
                    cpu_threads=getattr(settings, 'WHISPER_THREADS', 2)
                )
                logger.info(f"Whisperæ¨¡å‹ {settings.WHISPER_MODEL} åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise Exception(f"æ¨¡å‹æœªå®‰è£…æˆ–æŸåï¼Œè¯·å…ˆæ‰‹åŠ¨ä¸‹è½½æ¨¡å‹: {e}")
        return self.model
    
    def download_model(self):
        """æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹"""
        try:
            logger.info(f"å¼€å§‹ä¸‹è½½Whisperæ¨¡å‹: {settings.WHISPER_MODEL}")
            # è¿™ä¼šè§¦å‘æ¨¡å‹ä¸‹è½½
            model = WhisperModel(
                settings.WHISPER_MODEL,
                device=settings.WHISPER_DEVICE,
                compute_type=settings.WHISPER_COMPUTE_TYPE,
                num_workers=getattr(settings, 'WHISPER_NUM_WORKERS', 1),
                cpu_threads=getattr(settings, 'WHISPER_THREADS', 2)
            )
            self.model = model
            logger.info("æ¨¡å‹ä¸‹è½½å¹¶åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    async def download_video(self, url: str, video_id: int) -> Tuple[str, Dict]:
        """ä¸‹è½½è§†é¢‘å¹¶è·å–ä¿¡æ¯"""
        try:
            output_dir = Path(settings.VIDEO_DIR) / str(video_id)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # yt-dlp å‘½ä»¤
            cmd = [
                "yt-dlp",
                "--extract-flat",  # åªè·å–ä¿¡æ¯ï¼Œä¸ä¸‹è½½
                "--dump-json",
                url
            ]
            
            # è·å–è§†é¢‘ä¿¡æ¯
            result = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            stdout, stderr = await result.communicate()
            
            if result.returncode != 0:
                raise Exception(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {stderr.decode()}")
            
            video_info = json.loads(stdout.decode())
            
            # ä¸‹è½½è§†é¢‘
            download_cmd = [
                "yt-dlp",
                "--format", "best[height<=720]",  # é™åˆ¶ç”»è´¨ä»¥èŠ‚çœç©ºé—´
                "--output", str(output_dir / "%(title)s.%(ext)s"),
                "--write-thumbnail",
                url
            ]
            
            download_result = await asyncio.create_subprocess_exec(
                *download_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            await download_result.communicate()
            
            if download_result.returncode != 0:
                raise Exception("è§†é¢‘ä¸‹è½½å¤±è´¥")
            
            # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
            video_files = list(output_dir.glob("*"))
            video_file = next((f for f in video_files if f.suffix in ['.mp4', '.webm', '.mkv']), None)
            
            if not video_file:
                raise Exception("æœªæ‰¾åˆ°ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶")
            
            return str(video_file), {
                "title": video_info.get("title", ""),
                "duration": video_info.get("duration", 0),
                "thumbnail": video_info.get("thumbnail", ""),
                "platform": self._detect_platform(url)
            }
            
        except Exception as e:
            logger.error(f"ä¸‹è½½è§†é¢‘å¤±è´¥: {e}")
            raise
    
    async def extract_audio(self, video_path: str) -> str:
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        try:
            video_file = Path(video_path)
            audio_path = Path(settings.AUDIO_DIR) / f"{video_file.stem}.wav"
            
            # ç¡®ä¿éŸ³é¢‘ç›®å½•å­˜åœ¨
            audio_path.parent.mkdir(parents=True, exist_ok=True)
            
            # FFmpeg æå–éŸ³é¢‘
            cmd = [
                "ffmpeg",
                "-i", str(video_file),
                "-ac", "1",  # å•å£°é“
                "-ar", "16000",  # 16kHzé‡‡æ ·ç‡
                "-y",  # è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶
                str(audio_path)
            ]
            
            result = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            await result.communicate()
            
            if result.returncode != 0 or not audio_path.exists():
                raise Exception("éŸ³é¢‘æå–å¤±è´¥")
            
            return str(audio_path)
            
        except Exception as e:
            logger.error(f"æå–éŸ³é¢‘å¤±è´¥: {e}")
            raise
    
    async def transcribe_audio(self, audio_path: str) -> Dict:
        """è½¬å½•éŸ³é¢‘ä¸ºæ–‡å­—ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰"""
        async with transcription_semaphore:  # æ§åˆ¶å¹¶å‘æ•°é‡
            try:
                logger.info(f"å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_path} (å½“å‰å¯ç”¨æ§½ä½: {transcription_semaphore._value})")
                
                if not self.model:
                    self._ensure_model_loaded()
                
                # æ‰§è¡Œè½¬å½•
                segments, info = self.model.transcribe(audio_path)
                
                # æ”¶é›†è½¬å½•ç»“æœ
                transcript_segments = []
                full_text = ""
                
                for segment in segments:
                    segment_data = {
                        "start": segment.start,
                        "end": segment.end,
                        "text": segment.text.strip()
                    }
                    transcript_segments.append(segment_data)
                    full_text += segment.text.strip() + " "
                
                # æ¸…ç†æ–‡æœ¬
                cleaned_text = self._clean_text(full_text)
                
                # ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾
                summary = self._generate_summary(cleaned_text)
                tags = self._extract_tags(cleaned_text)
                
                logger.info(f"è½¬å½•å®Œæˆï¼Œå…±è½¬å½• {len(transcript_segments)} ä¸ªç‰‡æ®µ (é‡Šæ”¾æ§½ä½)")
                
                return {
                    "original_text": full_text.strip(),
                    "cleaned_text": cleaned_text,
                    "summary": summary,
                    "tags": ", ".join(tags),
                    "language": info.language,
                    "confidence_score": info.language_probability,
                    "segments": transcript_segments
                }
                
            except Exception as e:
                logger.error(f"è½¬å½•éŸ³é¢‘å¤±è´¥: {e} (é‡Šæ”¾æ§½ä½)")
                raise
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        # å»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text)
        
        # å»é™¤å¸¸è§çš„æ— æ„ä¹‰è¯æ±‡
        noise_words = ['å—¯', 'å•Š', 'å‘ƒ', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ç„¶å']
        for word in noise_words:
            text = text.replace(word, '')
        
        # æ·»åŠ æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*', r'\1\n', text)
        
        return text.strip()
    
    def _generate_summary(self, text: str) -> str:
        """ç”Ÿæˆæ‘˜è¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œå¯åç»­ç”¨LLMä¼˜åŒ–ï¼‰"""
        sentences = text.split('ã€‚')
        # å–å‰3ä¸ªæœ‰æ•ˆå¥å­ä½œä¸ºæ‘˜è¦
        summary_sentences = [s.strip() for s in sentences[:3] if len(s.strip()) > 10]
        return 'ã€‚'.join(summary_sentences) + 'ã€‚'
    
    def _extract_tags(self, text: str) -> List[str]:
        """æå–å…³é”®è¯æ ‡ç­¾"""
        # ç®€å•çš„å…³é”®è¯æå–
        tech_keywords = [
            'Python', 'JavaScript', 'React', 'Vue', 'Node.js', 'Django', 'FastAPI',
            'Docker', 'Git', 'Linux', 'ç¼–ç¨‹', 'å¼€å‘', 'å‰ç«¯', 'åç«¯', 'æ•°æ®åº“',
            'éƒ¨ç½²', 'æµ‹è¯•', 'æ¡†æ¶', 'API', 'ç®—æ³•', 'æ•°æ®ç»“æ„'
        ]
        
        tags = []
        text_lower = text.lower()
        
        for keyword in tech_keywords:
            if keyword.lower() in text_lower or keyword in text:
                tags.append(keyword)
        
        return tags[:5]  # æœ€å¤šè¿”å›5ä¸ªæ ‡ç­¾
    
    def _detect_platform(self, url: str) -> str:
        """æ£€æµ‹è§†é¢‘å¹³å°"""
        url_lower = url.lower()
        
        if 'douyin.com' in url_lower or 'tiktok.com' in url_lower:
            return 'douyin'
        elif 'weixin' in url_lower or 'mp.weixin.qq.com' in url_lower:
            return 'weixin'
        elif 'bilibili.com' in url_lower:
            return 'bilibili'
        elif 'youtube.com' in url_lower or 'youtu.be' in url_lower:
            return 'youtube'
        elif 'xiaohongshu.com' in url_lower:
            return 'xiaohongshu'
        else:
            return 'unknown'
    
    async def cleanup_files(self, video_id: int):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            video_dir = Path(settings.VIDEO_DIR) / str(video_id)
            audio_files = Path(settings.AUDIO_DIR).glob(f"{video_id}_*.wav")
            
            # åˆ é™¤éŸ³é¢‘æ–‡ä»¶ï¼ˆä¿ç•™è§†é¢‘æ–‡ä»¶ç”¨äºåç»­éœ€è¦ï¼‰
            for audio_file in audio_files:
                if audio_file.exists():
                    audio_file.unlink()
            
            logger.info(f"æ¸…ç†è§†é¢‘ {video_id} çš„ä¸´æ—¶æ–‡ä»¶å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    async def transcribe_video(self, video_path: str) -> Dict:
        """ç›´æ¥è½¬å½•è§†é¢‘æ–‡ä»¶ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰"""
        async with transcription_semaphore:  # æ§åˆ¶å¹¶å‘æ•°é‡
            try:
                logger.info(f"å¼€å§‹è½¬å½•è§†é¢‘: {video_path} (å½“å‰å¯ç”¨æ§½ä½: {transcription_semaphore._value})")
                
                # æ ¹æ®é…ç½®é€‰æ‹©è½¬å½•æ–¹å¼ï¼Œæ”¯æŒè‡ªåŠ¨é™çº§
                if settings.TRANSCRIPTION_MODE == "openai":
                    logger.info("ğŸŒ === ä½¿ç”¨OpenAIäº‘ç«¯è½¬å½•æ¨¡å¼ === ğŸŒ")
                    logger.info(f"ğŸ“‚ è§†é¢‘æ–‡ä»¶: {video_path}")
                    logger.info(f"ğŸ”‘ APIç«¯ç‚¹: {settings.OPENAI_BASE_URL}")
                    try:
                        result = await self._transcribe_with_openai(video_path)
                        logger.info("âœ… === OpenAIäº‘ç«¯è½¬å½•å®Œæˆ === âœ…")
                        return result
                    except Exception as openai_error:
                        logger.error(f"âŒ OpenAIè½¬å½•å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å¼: {openai_error}")
                        logger.warning("ğŸ”„ === è‡ªåŠ¨é™çº§åˆ°æœ¬åœ°CPUè½¬å½•æ¨¡å¼ === ğŸ”„")
                        # è‡ªåŠ¨é™çº§åˆ°æœ¬åœ°æ¨¡å¼
                        result = await self._transcribe_with_local_model(video_path)
                        logger.info("âœ… === æœ¬åœ°CPUè½¬å½•å®Œæˆï¼ˆé™çº§æ¨¡å¼ï¼‰=== âœ…")
                        return result
                else:
                    logger.info("ğŸ’» === ä½¿ç”¨æœ¬åœ°CPUè½¬å½•æ¨¡å¼ === ğŸ’»")
                    logger.info(f"ğŸ“‚ è§†é¢‘æ–‡ä»¶: {video_path}")
                    logger.warning("âš ï¸  æ³¨æ„ï¼šæœ¬åœ°æ¨¡å¼å°†æ¶ˆè€—å¤§é‡CPUèµ„æºï¼")
                    result = await self._transcribe_with_local_model(video_path)
                    logger.info("âœ… === æœ¬åœ°CPUè½¬å½•å®Œæˆ === âœ…")
                    return result
                    
            except Exception as e:
                logger.error(f"è½¬å½•è§†é¢‘å¤±è´¥: {e} (é‡Šæ”¾æ§½ä½)")
                return {
                    "original_text": f"è½¬å½•å¤±è´¥: {str(e)}",
                    "cleaned_text": f"è½¬å½•å¤±è´¥: {str(e)}",
                    "summary": "è§†é¢‘è½¬å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                    "tags": "è½¬å½•å¤±è´¥",
                    "language": "zh",
                    "confidence_score": 0.0,
                    "segments": []
                }
    
    async def _transcribe_with_openai(self, video_path: str) -> Dict:
        """ä½¿ç”¨OpenAI APIè½¬å½•"""
        try:
            logger.info("æ­£åœ¨ä½¿ç”¨OpenAI Whisper APIè½¬å½•è§†é¢‘...")
            
            # å»¶è¿Ÿåˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
            global openai_client
            if openai_client is None:
                from openai import OpenAI
                openai_client = OpenAI(
                    api_key=settings.OPENAI_API_KEY,
                    base_url=settings.OPENAI_BASE_URL
                )
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å° (OpenAIé™åˆ¶25MB)
            file_size = os.path.getsize(video_path)
            if file_size > 25 * 1024 * 1024:  # 25MB
                # éœ€è¦å…ˆæå–éŸ³é¢‘å¹¶å‹ç¼©
                audio_path = await self.extract_audio(video_path)
                transcribe_file = audio_path
            else:
                transcribe_file = video_path
            
            # è°ƒç”¨OpenAI API
            with open(transcribe_file, "rb") as audio_file:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    response_format="verbose_json",
                    language="zh"
                )
            
            # å¤„ç†å“åº”
            full_text = transcript.text
            segments_data = []
            
            # å¦‚æœæœ‰segmentsä¿¡æ¯
            if hasattr(transcript, 'segments') and transcript.segments:
                for segment in transcript.segments:
                    segments_data.append({
                        "start": segment.get('start', 0),
                        "end": segment.get('end', 0),
                        "text": segment.get('text', '').strip()
                    })
            else:
                # å¦‚æœæ²¡æœ‰segmentsï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„segment
                segments_data.append({
                    "start": 0,
                    "end": 0,
                    "text": full_text
                })
            
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            if transcribe_file != video_path and os.path.exists(transcribe_file):
                os.remove(transcribe_file)
            
            # å¤„ç†æ–‡æœ¬
            cleaned_text = self._clean_text(full_text)
            summary = self._generate_summary(cleaned_text)
            tags = self._extract_tags(cleaned_text)
            
            logger.info(f"OpenAIè½¬å½•å®Œæˆï¼Œå…±{len(segments_data)}ä¸ªç‰‡æ®µ")
            
            return {
                "original_text": full_text,
                "cleaned_text": cleaned_text,
                "summary": summary,
                "tags": ", ".join(tags),
                "language": "zh",
                "confidence_score": 0.95,  # OpenAIé€šå¸¸å¾ˆå‡†ç¡®
                "segments": segments_data
            }
            
        except Exception as e:
            logger.error(f"OpenAIè½¬å½•å¤±è´¥: {e}")
            raise
    
    async def _transcribe_with_local_model(self, video_path: str) -> Dict:
        """ä½¿ç”¨æœ¬åœ°æ¨¡å‹è½¬å½•"""
        try:
            # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
            self._ensure_model_loaded()
            
            # faster-whisper å¯ä»¥ç›´æ¥å¤„ç†è§†é¢‘æ–‡ä»¶
            logger.info("æ­£åœ¨ä½¿ç”¨æœ¬åœ°Whisperæ¨¡å‹è½¬å½•è§†é¢‘...")
            segments, info = self.model.transcribe(
                video_path,
                language="zh",  # æŒ‡å®šä¸ºä¸­æ–‡
                task="transcribe"
            )
            
            # æ”¶é›†è½¬å½•ç»“æœ
            transcript_segments = []
            full_text = ""
            
            for segment in segments:
                segment_data = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                transcript_segments.append(segment_data)
                full_text += segment.text.strip() + " "
            
            if not full_text.strip():
                logger.warning("è½¬å½•ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯è§†é¢‘æ²¡æœ‰éŸ³é¢‘æˆ–éŸ³é¢‘è´¨é‡é—®é¢˜")
                return {
                    "original_text": "æœªæ£€æµ‹åˆ°éŸ³é¢‘å†…å®¹",
                    "cleaned_text": "æœªæ£€æµ‹åˆ°éŸ³é¢‘å†…å®¹",
                    "summary": "è¯¥è§†é¢‘å¯èƒ½æ²¡æœ‰éŸ³é¢‘å†…å®¹æˆ–éŸ³é¢‘è´¨é‡è¾ƒå·®",
                    "tags": "æ— éŸ³é¢‘",
                    "language": "zh",
                    "confidence_score": 0.0,
                    "segments": []
                }
            
            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self._clean_text(full_text)
            
            # ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾
            summary = self._generate_summary(cleaned_text)
            tags = self._extract_tags(cleaned_text)
            
            logger.info(f"æœ¬åœ°è½¬å½•å®Œæˆï¼Œå…±è½¬å½• {len(transcript_segments)} ä¸ªç‰‡æ®µ")
            
            return {
                "original_text": full_text.strip(),
                "cleaned_text": cleaned_text,
                "summary": summary,
                "tags": ", ".join(tags),
                "language": info.language,
                "confidence_score": info.language_probability,
                "segments": transcript_segments
            }
                
        except Exception as e:
            logger.error(f"è½¬å½•è§†é¢‘å¤±è´¥: {e} (é‡Šæ”¾æ§½ä½)")
            # è¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            return {
                "original_text": f"è½¬å½•å¤±è´¥: {str(e)}",
                "cleaned_text": f"è½¬å½•å¤±è´¥: {str(e)}",
                "summary": "è§†é¢‘è½¬å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                "tags": "è½¬å½•å¤±è´¥",
                "language": "zh",
                "confidence_score": 0.0,
                "segments": []
            }

# å…¨å±€æœåŠ¡å®ä¾‹
ai_service = AITranscriptionService()