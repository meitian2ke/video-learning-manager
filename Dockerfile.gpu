# GPUä¼˜åŒ–ç‰ˆDockerfile - ä¸“ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    ffmpeg \
    git \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å‡çº§pipï¼ˆç›´æ¥ä½¿ç”¨python3.11ï¼‰
RUN python3.11 -m pip install --upgrade pip

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# é…ç½®pipä½¿ç”¨å›½å†…é•œåƒæºï¼ˆå¤§å¹…æå‡ä¸‹è½½é€Ÿåº¦ï¼‰
RUN python3.11 -m pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple/ && \
    python3.11 -m pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn

# å®‰è£…PyTorch GPUç‰ˆæœ¬ï¼ˆä½¿ç”¨å›½å†…æº + CUDA 11.8ï¼‰
RUN python3.11 -m pip install torch torchvision torchaudio \
    -i https://pypi.tuna.tsinghua.edu.cn/simple/ \
    --extra-index-url https://download.pytorch.org/whl/cu118

# å…ˆå®‰è£…faster-whisperå’Œå…³é”®ä¾èµ–ï¼ˆç¡®ä¿å®‰è£…æˆåŠŸï¼‰
RUN python3.11 -m pip install faster-whisper==0.9.0 transformers huggingface-hub -i https://pypi.tuna.tsinghua.edu.cn/simple/

# å®‰è£…å…¶ä»–ä¾èµ–
RUN python3.11 -m pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY backend/ ./backend/

# åˆ›å»ºlocal-videosç›®å½•ï¼ˆé¿å…å¤åˆ¶ç©ºç›®å½•å¯¼è‡´çš„é—®é¢˜ï¼‰
RUN mkdir -p ./local-videos

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/data/uploads \
             /app/data/videos \
             /app/data/audios \
             /app/data/thumbnails \
             /app/data/local-videos \
             /app/logs

# é¢„ä¸‹è½½Whisperæ¨¡å‹ï¼ˆç¡®ä¿å®¹å™¨å¯åŠ¨æ—¶æ¨¡å‹å¯ç”¨ï¼‰
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface
RUN python3.11 -c "from faster_whisper import WhisperModel; print('ğŸ“¥ ä¸‹è½½mediumæ¨¡å‹...'); WhisperModel('medium', device='cpu'); print('ğŸ“¥ ä¸‹è½½large-v3æ¨¡å‹...'); WhisperModel('large-v3', device='cpu'); print('âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ')"

# è®¾ç½®æƒé™
RUN chmod -R 755 /app

# ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/backend
ENV ENVIRONMENT=production
ENV WHISPER_DEVICE=cuda
ENV WHISPER_COMPUTE_TYPE=float16
ENV WHISPER_MODEL=base
ENV MAX_CONCURRENT_TRANSCRIPTIONS=3
ENV FORCE_CPU_MODE=false

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python3.11", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]