"""
ç³»ç»Ÿèµ„æºç›‘æ§å·¥å…·
ç›‘æ§CPUã€GPUã€å†…å­˜ä½¿ç”¨æƒ…å†µ
"""
import psutil
import logging
from typing import Dict, Optional
import subprocess
import json

logger = logging.getLogger(__name__)

class SystemMonitor:
    def __init__(self):
        self.gpu_available = self._check_gpu_availability()
    
    def _check_gpu_availability(self) -> bool:
        """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥NVIDIA GPU
            result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0 and result.stdout.strip():
                logger.info(f"ğŸ® æ£€æµ‹åˆ°NVIDIA GPU: {result.stdout.strip()}")
                return True
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰CUDAæ”¯æŒ
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                logger.info(f"ğŸ® æ£€æµ‹åˆ°CUDA GPU: {gpu_name}")
                return True
        except ImportError:
            pass
        
        logger.info("ğŸ’» æœªæ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False
    
    def get_cpu_usage(self) -> float:
        """è·å–CPUä½¿ç”¨ç‡"""
        return psutil.cpu_percent(interval=1)
    
    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory = psutil.virtual_memory()
        return {
            "total": memory.total / (1024**3),  # GB
            "used": memory.used / (1024**3),    # GB
            "available": memory.available / (1024**3),  # GB
            "percent": memory.percent
        }
    
    def get_gpu_usage(self) -> Optional[Dict]:
        """è·å–GPUä½¿ç”¨æƒ…å†µ"""
        if not self.gpu_available:
            return None
        
        try:
            # ä½¿ç”¨nvidia-smiè·å–GPUä¿¡æ¯
            cmd = [
                'nvidia-smi', 
                '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',
                '--format=csv,nounits,noheader'
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0:
                data = result.stdout.strip().split(',')
                if len(data) >= 4:
                    return {
                        "utilization": float(data[0].strip()),
                        "memory_used": float(data[1].strip()),
                        "memory_total": float(data[2].strip()),
                        "temperature": float(data[3].strip())
                    }
        except (subprocess.TimeoutExpired, ValueError, IndexError) as e:
            logger.warning(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
        
        # å°è¯•ä½¿ç”¨PyTorchè·å–GPUä¿¡æ¯
        try:
            import torch
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                gpu_allocated = torch.cuda.memory_allocated(0) / (1024**3)
                return {
                    "memory_total": gpu_memory,
                    "memory_used": gpu_allocated,
                    "memory_available": gpu_memory - gpu_allocated,
                    "utilization": "N/A"
                }
        except ImportError:
            pass
        
        return None
    
    def get_system_status(self) -> Dict:
        """è·å–å®Œæ•´çš„ç³»ç»ŸçŠ¶æ€"""
        cpu_usage = self.get_cpu_usage()
        memory_info = self.get_memory_usage()
        gpu_info = self.get_gpu_usage()
        
        # åˆ¤æ–­ç³»ç»Ÿè´Ÿè½½çŠ¶æ€
        load_status = "low"
        if cpu_usage > 80:
            load_status = "high"
        elif cpu_usage > 50:
            load_status = "medium"
        
        return {
            "timestamp": psutil.boot_time(),
            "cpu": {
                "usage_percent": cpu_usage,
                "load_avg": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None,
                "cores": psutil.cpu_count()
            },
            "memory": memory_info,
            "gpu": gpu_info,
            "load_status": load_status,
            "gpu_available": self.gpu_available
        }
    
    def is_suitable_for_transcription(self) -> tuple[bool, str]:
        """åˆ¤æ–­å½“å‰ç³»ç»ŸçŠ¶æ€æ˜¯å¦é€‚åˆè¿›è¡Œè½¬å½•ä»»åŠ¡"""
        status = self.get_system_status()
        
        cpu_usage = status["cpu"]["usage_percent"]
        memory_percent = status["memory"]["percent"]
        
        # å¼€å‘ç¯å¢ƒçš„è´Ÿè½½æ£€æŸ¥ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        if not self.gpu_available:
            if cpu_usage > 70:
                return False, f"CPUè´Ÿè½½è¿‡é«˜ ({cpu_usage:.1f}%)ï¼Œå»ºè®®ç­‰å¾…"
            if memory_percent > 85:
                return False, f"å†…å­˜ä¸è¶³ ({memory_percent:.1f}%)ï¼Œå»ºè®®ç­‰å¾…"
            return True, f"ç³»ç»Ÿè´Ÿè½½æ­£å¸¸ (CPU: {cpu_usage:.1f}%, å†…å­˜: {memory_percent:.1f}%)"
        
        # ç”Ÿäº§ç¯å¢ƒçš„è´Ÿè½½æ£€æŸ¥ï¼ˆç›¸å¯¹å®½æ¾ï¼‰
        else:
            if cpu_usage > 90:
                return False, f"CPUè´Ÿè½½æé«˜ ({cpu_usage:.1f}%)ï¼Œå»ºè®®ç­‰å¾…"
            if memory_percent > 95:
                return False, f"å†…å­˜ä¸¥é‡ä¸è¶³ ({memory_percent:.1f}%)ï¼Œå»ºè®®ç­‰å¾…"
            return True, f"GPUç¯å¢ƒè´Ÿè½½æ­£å¸¸ (CPU: {cpu_usage:.1f}%, å†…å­˜: {memory_percent:.1f}%)"
    
    def log_system_status(self):
        """è®°å½•ç³»ç»ŸçŠ¶æ€åˆ°æ—¥å¿—"""
        status = self.get_system_status()
        
        logger.info("ğŸ“Š === ç³»ç»ŸçŠ¶æ€ç›‘æ§ ===")
        logger.info(f"ğŸ’» CPUä½¿ç”¨ç‡: {status['cpu']['usage_percent']:.1f}%")
        logger.info(f"ğŸ§  å†…å­˜ä½¿ç”¨: {status['memory']['percent']:.1f}% ({status['memory']['used']:.1f}GB / {status['memory']['total']:.1f}GB)")
        
        if status['gpu']:
            gpu = status['gpu']
            logger.info(f"ğŸ® GPUä½¿ç”¨ç‡: {gpu.get('utilization', 'N/A')}%")
            logger.info(f"ğŸ® GPUå†…å­˜: {gpu.get('memory_used', 0):.1f}GB / {gpu.get('memory_total', 0):.1f}GB")
            if 'temperature' in gpu:
                logger.info(f"ğŸŒ¡ï¸ GPUæ¸©åº¦: {gpu['temperature']}Â°C")
        else:
            logger.info("ğŸ® GPU: æœªæ£€æµ‹åˆ°å¯ç”¨GPU")
        
        logger.info(f"ğŸ“ˆ ç³»ç»Ÿè´Ÿè½½çŠ¶æ€: {status['load_status']}")

# å…¨å±€ç›‘æ§å®ä¾‹
system_monitor = SystemMonitor()