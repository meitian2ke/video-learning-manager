"""
æœ¬åœ°è§†é¢‘ç®¡ç†API
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse
from typing import List, Dict, Any
import logging
import traceback
import torch
from pathlib import Path
from datetime import datetime, timedelta

from app.core.config import settings
from app.services.local_video_scanner import get_scanner
from app.core.database import get_db, Video, Transcript, SessionLocal
from sqlalchemy.orm import Session
from fastapi import Depends
import os

# å¯¼å…¥Celeryç›¸å…³
from app.tasks.video_tasks import process_video_task, batch_process_videos, get_task_status

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/scan")
async def scan_local_videos(background_tasks: BackgroundTasks):
    """æ‰«ææœ¬åœ°è§†é¢‘æ–‡ä»¶å¤¹"""
    try:
        logger.info(f"å¼€å§‹æ‰«ææœ¬åœ°è§†é¢‘ç›®å½•: {settings.LOCAL_VIDEO_DIR}")
        
        scanner = get_scanner(settings.LOCAL_VIDEO_DIR)
        if not scanner:
            logger.error("è§†é¢‘æ‰«æå™¨åˆå§‹åŒ–å¤±è´¥")
            raise HTTPException(status_code=500, detail="è§†é¢‘æ‰«æå™¨åˆå§‹åŒ–å¤±è´¥")
        
        # æ‰«æç°æœ‰è§†é¢‘
        video_files = await scanner.scan_existing_videos()
        logger.info(f"æ‰«æå®Œæˆï¼Œå‘ç° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        # è®°å½•å‘ç°çš„è§†é¢‘æ–‡ä»¶
        for i, video_file in enumerate(video_files, 1):
            logger.info(f"  {i}. {video_file}")
        
        # åå°å¤„ç†å‘ç°çš„è§†é¢‘
        for video_file in video_files:
            background_tasks.add_task(scanner.process_new_video, video_file)
        
        return {
            "message": f"æ‰«æå®Œæˆï¼Œå‘ç° {len(video_files)} ä¸ªæ–°è§†é¢‘",
            "video_count": len(video_files),
            "video_files": [os.path.basename(f) for f in video_files],
            "scan_directory": str(settings.LOCAL_VIDEO_DIR)
        }
    except Exception as e:
        logger.error(f"æ‰«ææœ¬åœ°è§†é¢‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰«æå¤±è´¥: {str(e)}")

@router.post("/start-watching")
async def start_watching():
    """å¼€å§‹ç›‘æ§æœ¬åœ°è§†é¢‘æ–‡ä»¶å¤¹"""
    try:
        scanner = get_scanner(settings.LOCAL_VIDEO_DIR)
        if not scanner:
            raise HTTPException(status_code=500, detail="è§†é¢‘æ‰«æå™¨åˆå§‹åŒ–å¤±è´¥")
        
        scanner.start_watching()
        
        return {
            "message": "æ–‡ä»¶å¤¹ç›‘æ§å·²å¯åŠ¨",
            "watch_directory": str(settings.LOCAL_VIDEO_DIR)
        }
    except Exception as e:
        logger.error(f"å¯åŠ¨æ–‡ä»¶å¤¹ç›‘æ§å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨ç›‘æ§å¤±è´¥: {str(e)}")

@router.post("/stop-watching")
async def stop_watching():
    """åœæ­¢ç›‘æ§æœ¬åœ°è§†é¢‘æ–‡ä»¶å¤¹"""
    try:
        scanner = get_scanner()
        if scanner:
            scanner.stop_watching()
        
        return {"message": "æ–‡ä»¶å¤¹ç›‘æ§å·²åœæ­¢"}
    except Exception as e:
        logger.error(f"åœæ­¢æ–‡ä»¶å¤¹ç›‘æ§å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åœæ­¢ç›‘æ§å¤±è´¥: {str(e)}")

@router.get("/list")
async def list_local_videos(db: Session = Depends(get_db)):
    """è·å–æœ¬åœ°è§†é¢‘æ–‡ä»¶åˆ—è¡¨ï¼ˆä¸æ•°æ®åº“çŠ¶æ€åŒæ­¥ï¼‰"""
    try:
        logger.info("å¼€å§‹è·å–æœ¬åœ°è§†é¢‘åˆ—è¡¨")
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        if not watch_dir.exists():
            return {"videos": [], "message": "ç›‘æ§ç›®å½•ä¸å­˜åœ¨"}
        
        video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.m4v'}
        videos = []
        
        # è·å–æ•°æ®åº“ä¸­çš„è§†é¢‘è®°å½•
        db_videos = {}
        for video in db.query(Video).filter(Video.platform == "local").all():
            if video.local_path:
                file_name = Path(video.local_path).name
                db_videos[file_name] = {
                    "id": video.id,
                    "status": video.status,
                    "title": video.title,
                    "url": video.url
                }
        
        for file_path in watch_dir.rglob('*'):
            if (file_path.is_file() and 
                file_path.suffix.lower() in video_extensions and
                not file_path.name.startswith('._') and  # è¿‡æ»¤macOSå…ƒæ•°æ®æ–‡ä»¶
                not file_path.name.startswith('.DS_Store')):
                stat = file_path.stat()
                file_name = file_path.name
                
                # ä»æ•°æ®åº“è·å–çŠ¶æ€ä¿¡æ¯
                db_info = db_videos.get(file_name, {})
                processing_status = "unprocessed"
                if db_info:
                    # æ˜ å°„æ•°æ®åº“çŠ¶æ€åˆ°å‰ç«¯çŠ¶æ€
                    status_mapping = {
                        "pending": "unprocessed",
                        "processing": "processing", 
                        "completed": "completed",
                        "failed": "failed"
                    }
                    processing_status = status_mapping.get(db_info["status"], "unprocessed")
                
                videos.append({
                    "name": file_name,
                    "title": db_info.get("title", file_path.stem),
                    "path": str(file_path),
                    "size": stat.st_size,
                    "size_mb": round(stat.st_size / (1024 * 1024), 2),
                    "modified_time": stat.st_mtime,
                    "extension": file_path.suffix.lower(),
                    "relative_path": str(file_path.relative_to(watch_dir)),
                    "processing_status": processing_status,
                    "progress": 100 if processing_status == "completed" else (None if processing_status == "processing" else 0),
                    "estimated_time": None,
                    "video_id": db_info.get("id"),
                    "db_status": db_info.get("status")
                })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        videos.sort(key=lambda x: x['modified_time'], reverse=True)
        
        return {
            "videos": videos,
            "total_count": len(videos),
            "watch_directory": str(settings.LOCAL_VIDEO_DIR)
        }
    except Exception as e:
        import traceback
        error_detail = f"è·å–æœ¬åœ°è§†é¢‘åˆ—è¡¨å¤±è´¥: {str(e)}"
        logger.error(f"{error_detail}\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=error_detail)

@router.get("/status")
async def get_scan_status():
    """è·å–æ‰«æçŠ¶æ€"""
    try:
        scanner = get_scanner()
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        
        return {
            "watch_directory": str(settings.LOCAL_VIDEO_DIR),
            "directory_exists": watch_dir.exists(),
            "is_watching": scanner is not None and scanner.observer and scanner.observer.is_alive() if scanner else False,
            "processed_count": len(scanner.processed_files) if scanner else 0
        }
    except Exception as e:
        logger.error(f"è·å–æ‰«æçŠ¶æ€å¤±è´¥: {e}")
        return {
            "watch_directory": str(settings.LOCAL_VIDEO_DIR),
            "directory_exists": False,
            "is_watching": False,
            "processed_count": 0,
            "error": str(e)
        }

@router.post("/debug-process/{video_name}")
async def debug_process_video(video_name: str, db: Session = Depends(get_db)):
    """Debugæ¨¡å¼å¤„ç†è§†é¢‘ - è¿”å›è¯¦ç»†æ­¥éª¤ä¿¡æ¯"""
    debug_steps = []
    video_path = None
    
    def add_debug_step(step: str, status: str, message: str, details: Dict[str, Any] = None):
        debug_steps.append({
            "step": step,
            "status": status,  # "success", "error", "running" 
            "message": message,
            "details": details or {},
            "timestamp": datetime.now().isoformat()
        })
    
    try:
        # æ­¥éª¤1: æ–‡ä»¶å®šä½
        add_debug_step("1_file_location", "running", "æ­£åœ¨å®šä½è§†é¢‘æ–‡ä»¶...")
        
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        
        for file_path in watch_dir.rglob('*'):
            if file_path.name == video_name:
                video_file = file_path
                break
        
        if not video_file:
            add_debug_step("1_file_location", "error", f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_name}")
            return {"video_name": video_name, "debug_steps": debug_steps}
        
        video_path = str(video_file)
        file_size = video_file.stat().st_size
        add_debug_step("1_file_location", "success", f"æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_path}", {
            "file_size": file_size,
            "file_size_mb": round(file_size / 1024 / 1024, 2)
        })
        
        # æ­¥éª¤2: ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥
        add_debug_step("2_system_check", "running", "æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ...")
        
        system_info = {
            "cuda_available": torch.cuda.is_available(),
            "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            "environment": settings.ENVIRONMENT,
            "whisper_model": settings.WHISPER_MODEL,
            "whisper_device": settings.WHISPER_DEVICE
        }
        
        if torch.cuda.is_available():
            system_info["gpu_name"] = torch.cuda.get_device_name(0)
            system_info["gpu_memory_allocated"] = torch.cuda.memory_allocated()
            system_info["gpu_memory_reserved"] = torch.cuda.memory_reserved()
        
        add_debug_step("2_system_check", "success", "ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥å®Œæˆ", system_info)
        
        # æ­¥éª¤3: æ¨¡å‹åŠ è½½æµ‹è¯•
        add_debug_step("3_model_loading", "running", "æµ‹è¯•æ¨¡å‹åŠ è½½...")
        
        from app.services.ai_service import ai_service
        
        try:
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„/åç§°
            model_path_or_name = ai_service._get_model_path_or_name()
            model_details = {
                "model_path_or_name": model_path_or_name,
                "is_local_path": model_path_or_name.startswith("/"),
                "device": ai_service._choose_device(),
                "compute_type": ai_service._choose_compute_type()
            }
            
            # å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if model_path_or_name.startswith("/"):
                model_details["path_exists"] = Path(model_path_or_name).exists()
            
            # å°è¯•åŠ è½½æ¨¡å‹
            ai_service._ensure_model_loaded()
            model_details["model_loaded"] = ai_service.model is not None
            model_details["model_type"] = type(ai_service.model).__name__ if ai_service.model else None
            
            add_debug_step("3_model_loading", "success", "æ¨¡å‹åŠ è½½æˆåŠŸ", model_details)
            
        except Exception as e:
            add_debug_step("3_model_loading", "error", f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}", {
                "error": str(e),
                "traceback": traceback.format_exc()
            })
            return {"video_name": video_name, "video_path": video_path, "debug_steps": debug_steps}
        
        # æ­¥éª¤4: è§†é¢‘å¤„ç†æµ‹è¯•
        add_debug_step("4_video_processing", "running", "å¼€å§‹è§†é¢‘å¤„ç†...")
        
        try:
            result = await ai_service.transcribe_video(video_path)
            
            processing_details = {
                "transcription_length": len(result.get("original_text", "")),
                "language": result.get("language", "unknown"),
                "confidence_score": result.get("confidence_score", 0),
                "segments_count": len(result.get("segments", [])),
                "has_summary": bool(result.get("summary")),
                "has_tags": bool(result.get("tags"))
            }
            
            add_debug_step("4_video_processing", "success", "è§†é¢‘å¤„ç†å®Œæˆ", processing_details)
            
            return {
                "video_name": video_name,
                "video_path": video_path,
                "debug_steps": debug_steps,
                "result": {
                    "original_text": result.get("original_text", "")[:200] + "..." if len(result.get("original_text", "")) > 200 else result.get("original_text", ""),
                    "summary": result.get("summary", ""),
                    "language": result.get("language", "unknown"),
                    "confidence_score": result.get("confidence_score", 0)
                }
            }
            
        except Exception as e:
            add_debug_step("4_video_processing", "error", f"è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}", {
                "error": str(e),
                "traceback": traceback.format_exc()
            })
            return {"video_name": video_name, "video_path": video_path, "debug_steps": debug_steps}
            
    except Exception as e:
        add_debug_step("system_error", "error", f"ç³»ç»Ÿé”™è¯¯: {str(e)}", {
            "error": str(e),
            "traceback": traceback.format_exc()
        })
        return {"video_name": video_name, "video_path": video_path, "debug_steps": debug_steps}

@router.post("/process/{video_name}")
async def process_local_video(video_name: str, db: Session = Depends(get_db)):
    """æäº¤æŒ‡å®šçš„æœ¬åœ°è§†é¢‘åˆ°Celeryé˜Ÿåˆ—å¤„ç†"""
    try:
        logger.info(f"ğŸ“¤ æäº¤è§†é¢‘å¤„ç†è¯·æ±‚: {video_name}")
        
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        
        for file_path in watch_dir.rglob('*'):
            if file_path.name == video_name:
                video_file = file_path
                break
        
        if not video_file:
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¿‡æ»¤macOSåƒåœ¾æ–‡ä»¶
        if video_file.name.startswith('._'):
            raise HTTPException(status_code=400, detail="ä¸èƒ½å¤„ç†macOSå…ƒæ•°æ®æ–‡ä»¶")
        
        logger.info(f"ğŸ“¹ æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_file}")
        
        # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨è®°å½•
        video_record = db.query(Video).filter(Video.local_path == str(video_file)).first()
        
        if not video_record:
            # åˆ›å»ºæ–°çš„è§†é¢‘è®°å½•
            file_stat = video_file.stat()
            video_record = Video(
                title=video_file.stem,  # æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                url=f"local://{video_name}",
                platform="local",
                local_path=str(video_file),
                file_size=file_stat.st_size,
                status="pending",
                retry_count=0
            )
            db.add(video_record)
            db.commit()
            db.refresh(video_record)
            logger.info(f"âœ… åˆ›å»ºè§†é¢‘è®°å½•: ID={video_record.id}")
        else:
            # æ›´æ–°çŠ¶æ€ä¸ºå¾…å¤„ç†
            video_record.status = "pending"
            video_record.retry_count = 0
            video_record.task_id = None
            db.commit()
            logger.info(f"ğŸ”„ é‡ç½®è§†é¢‘è®°å½•çŠ¶æ€: ID={video_record.id}")
        
        # æäº¤åˆ°Celeryé˜Ÿåˆ—
        task = process_video_task.delay(video_record.id)
        
        # æ›´æ–°ä»»åŠ¡ID
        video_record.task_id = task.id
        db.commit()
        
        logger.info(f"ğŸš€ è§†é¢‘å·²æäº¤åˆ°Celeryé˜Ÿåˆ—: task_id={task.id}")
        
        return {
            "message": f"è§†é¢‘ {video_name} å·²æäº¤åˆ°å¤„ç†é˜Ÿåˆ—",
            "video_name": video_name,
            "video_id": video_record.id,
            "task_id": task.id,
            "status": "pending"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æäº¤è§†é¢‘å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {e}")
        logger.error(f"ğŸ“‹ é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æäº¤å¤„ç†å¤±è´¥: {str(e)}")

@router.get("/model-status")
async def get_model_status():
    """è·å–æ¨¡å‹çŠ¶æ€ä¿¡æ¯"""
    try:
        from app.services.ai_service import ai_service
        
        status_info = {
            "model_name": settings.WHISPER_MODEL,
            "device": ai_service._choose_device(),
            "compute_type": ai_service._choose_compute_type(),
            "environment": ai_service.environment,
            "model_loaded": ai_service.model is not None,
            "cuda_available": torch.cuda.is_available(),
            "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0
        }
        
        # å°è¯•è·å–æ¨¡å‹è·¯å¾„ä¿¡æ¯
        try:
            model_path_or_name = ai_service._get_model_path_or_name()
            status_info["model_path_or_name"] = model_path_or_name
            
            if model_path_or_name.startswith("/"):
                status_info["is_local_model"] = True
                status_info["model_path_exists"] = Path(model_path_or_name).exists()
            else:
                status_info["is_local_model"] = False
        except Exception as e:
            status_info["model_path_error"] = str(e)
        
        # GPUä¿¡æ¯
        if torch.cuda.is_available():
            status_info["gpu_info"] = {
                "gpu_name": torch.cuda.get_device_name(0),
                "memory_allocated_mb": round(torch.cuda.memory_allocated() / 1024 / 1024, 2),
                "memory_reserved_mb": round(torch.cuda.memory_reserved() / 1024 / 1024, 2)
            }
        
        return status_info
        
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }

# æ—§çš„process_video_taskå‡½æ•°å·²ç§»è‡³app.tasks.video_tasksæ¨¡å—

@router.get("/processing-status")
async def get_processing_status(db: Session = Depends(get_db)):
    """è·å–æ‰€æœ‰è§†é¢‘çš„å¤„ç†çŠ¶æ€"""
    try:
        # è·å–å„ç§çŠ¶æ€çš„è§†é¢‘æ•°é‡å’Œè¯¦æƒ…
        processing_videos = db.query(Video).filter(
            Video.status.in_(["processing", "pending"])
        ).all()
        
        return {
            "processing_count": len(processing_videos),
            "videos": [{
                "id": v.id,
                "title": v.title,
                "status": v.status
            } for v in processing_videos]
        }
    except Exception as e:
        logger.error(f"è·å–å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/quick-debug/{video_name}")
async def quick_debug_video(video_name: str):
    """å¿«é€Ÿdebugæ¥å£ - åªæ£€æŸ¥åŸºç¡€ä¿¡æ¯"""
    try:
        # æ–‡ä»¶æ£€æŸ¥
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        
        for file_path in watch_dir.rglob('*'):
            if file_path.name == video_name:
                video_file = file_path
                break
        
        if not video_file:
            return {"error": f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_name}"}
        
        # åŸºç¡€ä¿¡æ¯
        file_size = video_file.stat().st_size
        
        # æ¨¡å‹çŠ¶æ€å¿«é€Ÿæ£€æŸ¥
        from app.services.ai_service import ai_service
        
        quick_info = {
            "video_found": True,
            "video_path": str(video_file),
            "file_size_mb": round(file_size / 1024 / 1024, 2),
            "cuda_available": torch.cuda.is_available(),
            "model_loaded": ai_service.model is not None,
            "whisper_device": settings.WHISPER_DEVICE,
            "whisper_model": settings.WHISPER_MODEL
        }
        
        return quick_info
        
    except Exception as e:
        return {
            "error": str(e),
            "video_name": video_name
        }

@router.post("/deep-debug/{video_name}")
async def deep_debug_whisper(video_name: str):
    """æ·±åº¦debug faster-whisperéŸ³é¢‘ç»´åº¦é—®é¢˜"""
    try:
        from app.services.ai_service import ai_service
        import torch
        from pathlib import Path
        
        # æ–‡ä»¶æ£€æŸ¥
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        for file_path in watch_dir.rglob('*'):
            if file_path.name == video_name:
                video_file = file_path
                break
        
        if not video_file:
            return {"error": f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_name}"}
        
        video_path = str(video_file)
        debug_info = {
            "video_file": video_path,
            "file_size_mb": round(video_file.stat().st_size / 1024 / 1024, 2),
            "steps": []
        }
        
        # æ­¥éª¤1: æ£€æŸ¥æ¨¡å‹çŠ¶æ€
        debug_info["steps"].append({
            "step": "model_check",
            "model_loaded": ai_service.model is not None,
            "device": ai_service._choose_device(),
            "compute_type": ai_service._choose_compute_type()
        })
        
        # æ­¥éª¤2: å°è¯•åŠ è½½æ¨¡å‹
        try:
            ai_service._ensure_model_loaded()
            debug_info["steps"].append({
                "step": "model_loaded",
                "status": "success",
                "model_type": type(ai_service.model).__name__
            })
        except Exception as e:
            debug_info["steps"].append({
                "step": "model_load_failed",
                "status": "error",
                "error": str(e)
            })
            return debug_info
        
        # æ­¥éª¤3: æµ‹è¯•ä¸åŒå‚æ•°çš„è½¬å½•
        test_params = [
            {"name": "default", "params": {"language": "zh", "task": "transcribe"}},
            {"name": "auto_detect", "params": {"task": "transcribe"}},
            {"name": "english", "params": {"language": "en", "task": "transcribe"}},
            {"name": "no_language", "params": {"task": "transcribe", "beam_size": 1}}
        ]
        
        for test in test_params:
            try:
                segments, info = ai_service.model.transcribe(video_path, **test["params"])
                
                # æ”¶é›†ä¸€äº›ç»“æœ
                segment_count = 0
                first_text = ""
                for segment in segments:
                    segment_count += 1
                    if segment_count == 1:
                        first_text = segment.text[:50]  # åªå–å‰50ä¸ªå­—ç¬¦
                    if segment_count >= 3:  # åªå¤„ç†å‰3ä¸ªç‰‡æ®µ
                        break
                
                debug_info["steps"].append({
                    "step": f"transcribe_{test['name']}",
                    "status": "success",
                    "params": test["params"],
                    "language_detected": info.language,
                    "confidence": info.language_probability,
                    "duration": info.duration,
                    "segments_processed": segment_count,
                    "first_text": first_text
                })
                
                # å¦‚æœæˆåŠŸï¼Œç›´æ¥è¿”å›
                return debug_info
                
            except Exception as e:
                debug_info["steps"].append({
                    "step": f"transcribe_{test['name']}",
                    "status": "error",
                    "params": test["params"],
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                continue
        
        return debug_info
        
    except Exception as e:
        return {
            "error": str(e),
            "video_name": video_name,
            "error_type": type(e).__name__
        }

        processing_videos = db.query(Video).filter(
            Video.platform == "local",
            Video.status == "processing"
        ).all()
        
        pending_videos = db.query(Video).filter(
            Video.platform == "local", 
            Video.status == "pending"
        ).all()
        
        completed_count = db.query(Video).filter(
            Video.platform == "local",
            Video.status == "completed"
        ).count()
        
        failed_count = db.query(Video).filter(
            Video.platform == "local",
            Video.status == "failed"
        ).count()
        
        processing_details = []
        for video in processing_videos:
            processing_details.append({
                "id": video.id,
                "title": video.title,
                "file_size_mb": round(video.file_size / (1024*1024), 2) if video.file_size else 0,
                "updated_at": video.updated_at,
                "local_path": Path(video.local_path).name if video.local_path else ""
            })
        
        pending_details = []
        for video in pending_videos:
            pending_details.append({
                "id": video.id,
                "title": video.title,
                "file_size_mb": round(video.file_size / (1024*1024), 2) if video.file_size else 0,
                "created_at": video.created_at,
                "local_path": Path(video.local_path).name if video.local_path else ""
            })
        
        return {
            "processing_videos": processing_details,
            "pending_videos": pending_details,
            "processing_count": len(processing_videos),
            "pending_count": len(pending_videos),
            "completed_count": completed_count,
            "failed_count": failed_count,
            "total_local_videos": completed_count + failed_count + len(processing_videos) + len(pending_videos)
        }
    except Exception as e:
        logger.error(f"è·å–å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")

@router.delete("/delete/{video_name}")
async def delete_local_video(video_name: str):
    """åˆ é™¤æœ¬åœ°è§†é¢‘æ–‡ä»¶"""
    try:
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        for file_path in watch_dir.rglob('*'):
            if file_path.name == video_name:
                video_file = file_path
                break
        
        if not video_file:
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # åˆ é™¤æ–‡ä»¶
        video_file.unlink()
        logger.info(f"å·²åˆ é™¤æœ¬åœ°è§†é¢‘æ–‡ä»¶: {video_file}")
        
        return {
            "message": f"è§†é¢‘æ–‡ä»¶ {video_name} åˆ é™¤æˆåŠŸ",
            "deleted_file": str(video_file)
        }
        
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    except PermissionError:
        raise HTTPException(status_code=403, detail="æ²¡æœ‰åˆ é™¤æƒé™")
    except Exception as e:
        logger.error(f"åˆ é™¤æœ¬åœ°è§†é¢‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

@router.get("/file/{file_name}")
async def serve_video_file(file_name: str):
    """æä¾›æœ¬åœ°è§†é¢‘æ–‡ä»¶çš„HTTPè®¿é—®"""
    try:
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        for file_path in watch_dir.rglob('*'):
            if file_path.name == file_name:
                video_file = file_path
                break
        
        if not video_file or not video_file.exists():
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.m4v'}
        if video_file.suffix.lower() not in video_extensions:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
        
        # è¿”å›æ–‡ä»¶
        return FileResponse(
            path=str(video_file),
            media_type="video/mp4",
            filename=video_file.name
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æä¾›è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶æœåŠ¡å¤±è´¥: {str(e)}")

@router.get("/video-detail/{video_id}")
async def get_video_detail(video_id: int, db: Session = Depends(get_db)):
    """è·å–è§†é¢‘å¤„ç†è¯¦æƒ…"""
    try:
        # æŸ¥æ‰¾è§†é¢‘è®°å½•
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # æŸ¥æ‰¾å­—å¹•è®°å½•
        transcript = db.query(Transcript).filter(Transcript.video_id == video_id).first()
        
        return {
            "video": {
                "id": video.id,
                "title": video.title,
                "platform": video.platform,
                "status": video.status,
                "url": video.url,
                "local_path": video.local_path,
                "file_fingerprint": video.file_fingerprint,
                "duration": video.duration,
                "file_size": video.file_size,
                "retry_count": video.retry_count,
                "created_at": video.created_at,
                "updated_at": video.updated_at
            },
            "transcript": {
                "id": transcript.id if transcript else None,
                "original_text": transcript.original_text if transcript else None,
                "cleaned_text": transcript.cleaned_text if transcript else None,
                "summary": transcript.summary if transcript else None,
                "tags": transcript.tags if transcript else None,
                "language": transcript.language if transcript else None,
                "confidence_score": transcript.confidence_score if transcript else None,
                "processing_time": transcript.processing_time if transcript else None,
                "created_at": transcript.created_at if transcript else None
            } if transcript else None,
            "has_transcript": transcript is not None
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥: {str(e)}")

@router.post("/reset-failed")
async def reset_failed_videos(db: Session = Depends(get_db)):
    """é‡ç½®æ‰€æœ‰å¤±è´¥çš„è§†é¢‘çŠ¶æ€ï¼Œå…è®¸é‡æ–°å¤„ç†"""
    try:
        # æŸ¥æ‰¾æ‰€æœ‰å¤±è´¥çš„æœ¬åœ°è§†é¢‘
        failed_videos = db.query(Video).filter(
            Video.platform == "local",
            Video.status == "failed"
        ).all()
        
        reset_count = 0
        for video in failed_videos:
            video.status = "pending"
            video.retry_count = 0  # é‡ç½®é‡è¯•æ¬¡æ•°
            reset_count += 1
        
        db.commit()
        
        logger.info(f"å·²é‡ç½® {reset_count} ä¸ªå¤±è´¥è§†é¢‘çš„çŠ¶æ€")
        
        return {
            "message": f"å·²é‡ç½® {reset_count} ä¸ªå¤±è´¥è§†é¢‘ï¼Œå¯é‡æ–°å¤„ç†",
            "reset_count": reset_count
        }
        
    except Exception as e:
        logger.error(f"é‡ç½®å¤±è´¥è§†é¢‘çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é‡ç½®å¤±è´¥: {str(e)}")

@router.post("/reset-video/{video_name}")
async def reset_single_video(video_name: str, db: Session = Depends(get_db)):
    """é‡ç½®å•ä¸ªè§†é¢‘çš„å¤±è´¥çŠ¶æ€"""
    try:
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        video_file = None
        
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        for file_path in watch_dir.rglob('*'):
            if file_path.name == video_name:
                video_file = file_path
                break
        
        if not video_file:
            raise HTTPException(status_code=404, detail="è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æŸ¥æ‰¾æ•°æ®åº“è®°å½•
        video = db.query(Video).filter(Video.local_path == str(video_file)).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘è®°å½•ä¸å­˜åœ¨")
        
        # é‡ç½®çŠ¶æ€
        video.status = "pending"
        video.retry_count = 0
        db.commit()
        
        logger.info(f"å·²é‡ç½®è§†é¢‘çŠ¶æ€: {video_name}")
        
        return {
            "message": f"è§†é¢‘ {video_name} çŠ¶æ€å·²é‡ç½®ï¼Œå¯é‡æ–°å¤„ç†",
            "video_id": video.id,
            "status": "pending"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡ç½®è§†é¢‘çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é‡ç½®å¤±è´¥: {str(e)}")

@router.get("/logs")
async def get_processing_logs():
    """è·å–è§†é¢‘å¤„ç†æ—¥å¿—"""
    try:
        from app.core.config import settings
        import os
        
        # è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„
        log_dir = Path(settings.UPLOAD_DIR).parent / "logs"
        log_file = log_dir / "video_processing.log"
        
        if not log_file.exists():
            return {
                "logs": [],
                "message": "æš‚æ— å¤„ç†æ—¥å¿—"
            }
        
        # è¯»å–æœ€æ–°çš„100è¡Œæ—¥å¿—
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            recent_logs = lines[-100:] if len(lines) > 100 else lines
        
        return {
            "logs": [line.strip() for line in recent_logs],
            "total_lines": len(lines),
            "showing_recent": len(recent_logs)
        }
        
    except Exception as e:
        logger.error(f"è·å–å¤„ç†æ—¥å¿—å¤±è´¥: {e}")
        return {
            "logs": [f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}"],
            "error": True
        }

@router.get("/logs/live")
async def get_live_logs():
    """è·å–å®æ—¶å¤„ç†æ—¥å¿—ï¼ˆæœ€æ–°50è¡Œï¼‰"""
    try:
        from app.core.config import settings
        
        log_dir = Path(settings.UPLOAD_DIR).parent / "logs"
        log_file = log_dir / "video_processing.log"
        
        if not log_file.exists():
            return {"logs": ["æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"]}
        
        # è¯»å–æœ€æ–°çš„50è¡Œ
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            recent_logs = lines[-50:] if len(lines) > 50 else lines
        
        return {
            "logs": [line.strip() for line in recent_logs if line.strip()],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"è·å–å®æ—¶æ—¥å¿—å¤±è´¥: {e}")
        return {"logs": [f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}"]}

@router.get("/task-status/{task_id}")
async def get_celery_task_status(task_id: str):
    """è·å–Celeryä»»åŠ¡çŠ¶æ€"""
    try:
        from celery.result import AsyncResult
        from app.celery_app import celery_app
        
        result = AsyncResult(task_id, app=celery_app)
        
        return {
            "task_id": task_id,
            "status": result.status,
            "result": result.result if result.ready() else None,
            "info": result.info,
            "traceback": result.traceback if result.failed() else None
        }
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return {
            "task_id": task_id,
            "status": "ERROR",
            "error": str(e)
        }

@router.post("/batch-process")
async def batch_process_videos_api(video_names: List[str], db: Session = Depends(get_db)):
    """æ‰¹é‡å¤„ç†è§†é¢‘"""
    try:
        logger.info(f"ğŸ“¦ æ‰¹é‡å¤„ç†è¯·æ±‚: {len(video_names)} ä¸ªè§†é¢‘")
        
        video_ids = []
        watch_dir = Path(settings.LOCAL_VIDEO_DIR)
        
        # éªŒè¯æ‰€æœ‰è§†é¢‘æ–‡ä»¶å­˜åœ¨å¹¶åˆ›å»ºè®°å½•
        for video_name in video_names:
            # è·³è¿‡macOSåƒåœ¾æ–‡ä»¶
            if video_name.startswith('._'):
                logger.warning(f"âš ï¸ è·³è¿‡macOSå…ƒæ•°æ®æ–‡ä»¶: {video_name}")
                continue
                
            # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
            video_file = None
            for file_path in watch_dir.rglob('*'):
                if file_path.name == video_name:
                    video_file = file_path
                    break
            
            if not video_file:
                logger.warning(f"âš ï¸ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_name}")
                continue
            
            # æ£€æŸ¥æˆ–åˆ›å»ºè§†é¢‘è®°å½•
            video_record = db.query(Video).filter(Video.local_path == str(video_file)).first()
            
            if not video_record:
                file_stat = video_file.stat()
                video_record = Video(
                    title=video_file.stem,
                    url=f"local://{video_name}",
                    platform="local",
                    local_path=str(video_file),
                    file_size=file_stat.st_size,
                    status="pending",
                    retry_count=0
                )
                db.add(video_record)
                db.flush()  # è·å–IDä½†ä¸æäº¤
            else:
                # é‡ç½®çŠ¶æ€
                video_record.status = "pending"
                video_record.retry_count = 0
                video_record.task_id = None
            
            video_ids.append(video_record.id)
        
        db.commit()
        
        # æäº¤æ‰¹é‡å¤„ç†ä»»åŠ¡
        task = batch_process_videos.delay(video_ids)
        
        logger.info(f"ğŸš€ æ‰¹é‡å¤„ç†ä»»åŠ¡å·²æäº¤: task_id={task.id}, è§†é¢‘æ•°é‡={len(video_ids)}")
        
        return {
            "message": f"å·²æäº¤ {len(video_ids)} ä¸ªè§†é¢‘åˆ°æ‰¹é‡å¤„ç†é˜Ÿåˆ—",
            "task_id": task.id,
            "video_count": len(video_ids),
            "skipped_count": len(video_names) - len(video_ids)
        }
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å¤„ç†æäº¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")

@router.get("/queue-status")
async def get_queue_status():
    """è·å–Celeryé˜Ÿåˆ—çŠ¶æ€"""
    try:
        from app.celery_app import celery_app
        
        inspect = celery_app.control.inspect()
        
        # è·å–æ´»è·ƒä»»åŠ¡
        active_tasks = inspect.active()
        
        # è·å–é¢„å®šä»»åŠ¡
        scheduled_tasks = inspect.scheduled()
        
        # è·å–ä¿ç•™ä»»åŠ¡
        reserved_tasks = inspect.reserved()
        
        return {
            "active_tasks": active_tasks,
            "scheduled_tasks": scheduled_tasks,
            "reserved_tasks": reserved_tasks,
            "worker_stats": inspect.stats()
        }
        
    except Exception as e:
        logger.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return {
            "error": str(e),
            "message": "æ— æ³•è¿æ¥åˆ°Celery"
        }

@router.get("/debug-system")
async def debug_system_status():
    """è°ƒè¯•ç³»ç»ŸçŠ¶æ€ - æ£€æŸ¥GPUã€æ¨¡å‹ã€é˜Ÿåˆ—ç­‰"""
    try:
        import torch
        import psutil
        from app.services.ai_service import ai_service
        
        debug_info = {
            "timestamp": datetime.now().isoformat(),
            "system": {
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_usage": psutil.disk_usage('/').percent
            },
            "gpu": {
                "available": torch.cuda.is_available(),
                "device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0
            },
            "whisper": {
                "model_loaded": ai_service.model is not None,
                "model_name": settings.WHISPER_MODEL,
                "device": settings.WHISPER_DEVICE,
                "compute_type": settings.WHISPER_COMPUTE_TYPE
            },
            "environment": {
                "transcription_mode": settings.TRANSCRIPTION_MODE,
                "max_concurrent": settings.MAX_CONCURRENT_TRANSCRIPTIONS,
                "queue_size": settings.TRANSCRIPTION_QUEUE_SIZE
            }
        }
        
        # GPUè¯¦ç»†ä¿¡æ¯
        if torch.cuda.is_available():
            debug_info["gpu"].update({
                "name": torch.cuda.get_device_name(0),
                "memory_allocated_mb": round(torch.cuda.memory_allocated() / 1024 / 1024, 2),
                "memory_reserved_mb": round(torch.cuda.memory_reserved() / 1024 / 1024, 2),
                "memory_total_mb": round(torch.cuda.get_device_properties(0).total_memory / 1024 / 1024, 2)
            })
        
        # æ£€æŸ¥å¤„ç†é˜Ÿåˆ—çŠ¶æ€
        with SessionLocal() as db:
            queue_status = {
                "pending": db.query(Video).filter(Video.status == "pending", Video.platform == "local").count(),
                "processing": db.query(Video).filter(Video.status == "processing", Video.platform == "local").count(),
                "completed": db.query(Video).filter(Video.status == "completed", Video.platform == "local").count(),
                "failed": db.query(Video).filter(Video.status == "failed", Video.platform == "local").count()
            }
            debug_info["queue"] = queue_status
        
        return debug_info
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿè°ƒè¯•ä¿¡æ¯å¤±è´¥: {e}")
        return {
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@router.post("/force-reset-processing")
async def force_reset_processing(db: Session = Depends(get_db)):
    """å¼ºåˆ¶é‡ç½®æ‰€æœ‰å¤„ç†ä¸­çŠ¶æ€çš„è§†é¢‘ - è§£å†³é˜Ÿåˆ—å¡ä½é—®é¢˜"""
    try:
        # æŸ¥æ‰¾æ‰€æœ‰å¤„ç†ä¸­çš„æœ¬åœ°è§†é¢‘
        processing_videos = db.query(Video).filter(
            Video.platform == "local",
            Video.status == "processing"
        ).all()
        
        reset_count = 0
        for video in processing_videos:
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦çœŸçš„è¿˜åœ¨å¤„ç†ä¸­ï¼ˆç®€å•æ£€æŸ¥ï¼šè¶…è¿‡30åˆ†é’Ÿçš„å¤„ç†è®¤ä¸ºæ˜¯å¡ä½äº†ï¼‰
            if video.updated_at:
                time_diff = datetime.utcnow() - video.updated_at
                if time_diff.total_seconds() > 1800:  # 30åˆ†é’Ÿ
                    video.status = "pending"
                    video.retry_count = (video.retry_count or 0) + 1
                    reset_count += 1
                    logger.info(f"å¼ºåˆ¶é‡ç½®å¡ä½çš„è§†é¢‘: {video.title} (è¶…æ—¶: {time_diff.total_seconds()}ç§’)")
            else:
                # æ²¡æœ‰æ›´æ–°æ—¶é—´çš„ç›´æ¥é‡ç½®
                video.status = "pending"
                video.retry_count = (video.retry_count or 0) + 1
                reset_count += 1
                logger.info(f"å¼ºåˆ¶é‡ç½®æ— æ—¶é—´æˆ³çš„è§†é¢‘: {video.title}")
        
        db.commit()
        
        logger.info(f"å¼ºåˆ¶é‡ç½®äº† {reset_count} ä¸ªå¡ä½çš„å¤„ç†ä¸­è§†é¢‘")
        
        return {
            "message": f"å·²å¼ºåˆ¶é‡ç½® {reset_count} ä¸ªå¤„ç†ä¸­è§†é¢‘ï¼Œé˜Ÿåˆ—åº”è¯¥æ¢å¤æ­£å¸¸",
            "reset_count": reset_count,
            "total_processing": len(processing_videos)
        }
        
    except Exception as e:
        logger.error(f"å¼ºåˆ¶é‡ç½®å¤„ç†ä¸­è§†é¢‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¼ºåˆ¶é‡ç½®å¤±è´¥: {str(e)}")

@router.post("/clear-gpu-memory")
async def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜ï¼Œé‡Šæ”¾å¯èƒ½å¡ä½çš„æ¨¡å‹"""
    try:
        import torch
        from app.services.ai_service import ai_service
        
        # æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
            
        # é‡æ–°åˆå§‹åŒ–æ¨¡å‹
        ai_service.model = None
        
        memory_info = {}
        if torch.cuda.is_available():
            memory_info = {
                "memory_allocated_mb": round(torch.cuda.memory_allocated() / 1024 / 1024, 2),
                "memory_reserved_mb": round(torch.cuda.memory_reserved() / 1024 / 1024, 2),
                "memory_total_mb": round(torch.cuda.get_device_properties(0).total_memory / 1024 / 1024, 2)
            }
        
        logger.info("å·²æ¸…ç†GPUå†…å­˜å¹¶é‡ç½®Whisperæ¨¡å‹")
        
        return {
            "message": "GPUå†…å­˜å·²æ¸…ç†ï¼ŒWhisperæ¨¡å‹å·²é‡ç½®",
            "gpu_memory": memory_info
        }
        
    except Exception as e:
        logger.error(f"æ¸…ç†GPUå†…å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†GPUå†…å­˜å¤±è´¥: {str(e)}")

@router.get("/check-stuck-videos")
async def check_stuck_videos(db: Session = Depends(get_db)):
    """æ£€æŸ¥å¯èƒ½å¡ä½çš„è§†é¢‘"""
    try:
        from datetime import timedelta
        
        # æŸ¥æ‰¾è¶…è¿‡30åˆ†é’Ÿè¿˜åœ¨å¤„ç†ä¸­çš„è§†é¢‘
        thirty_minutes_ago = datetime.utcnow() - timedelta(minutes=30)
        
        stuck_videos = db.query(Video).filter(
            Video.platform == "local",
            Video.status == "processing",
            Video.updated_at < thirty_minutes_ago
        ).all()
        
        stuck_info = []
        for video in stuck_videos:
            time_diff = datetime.utcnow() - video.updated_at if video.updated_at else None
            stuck_info.append({
                "id": video.id,
                "title": video.title,
                "local_path": video.local_path,
                "status": video.status,
                "retry_count": video.retry_count or 0,
                "updated_at": video.updated_at.isoformat() if video.updated_at else None,
                "stuck_duration_minutes": int(time_diff.total_seconds() / 60) if time_diff else None
            })
        
        return {
            "stuck_videos": stuck_info,
            "stuck_count": len(stuck_videos),
            "message": f"å‘ç° {len(stuck_videos)} ä¸ªå¯èƒ½å¡ä½çš„è§†é¢‘"
        }
        
    except Exception as e:
        logger.error(f"æ£€æŸ¥å¡ä½è§†é¢‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€æŸ¥å¤±è´¥: {str(e)}")